{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "  Downloading kfp-1.6.4.tar.gz (225 kB)\n",
      "\u001b[K     |████████████████████████████████| 225 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py<=0.11,>=0.9\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 69.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.38.0)\n",
      "Collecting kubernetes<13,>=8.0.0\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 47.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 43 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.30.2)\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.6.0)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.6.0.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting click<8,>=7.1.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.8.1.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2.0,>=0.1.8\n",
      "  Downloading kfp_pipeline_spec-0.1.8-py3-none-any.whl (27 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.16.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (3.0.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (1.30.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.53.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (20.9)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2021.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.2)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (1.7.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage<2,>=1.20.0->kfp) (2.20)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (4.5.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.5)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.5.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<13,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<13,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (4.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.36.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.10.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<13,>=8.0.0->kfp) (3.1.1)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, strip-hints, termcolor\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.6.4-py3-none-any.whl size=307978 sha256=1393274678f3592b858fb67c421c33399cd6ae62cc2ebb1d9155d38312ed1513\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/68/fb/ec/d4c6e6c3a85acbf75cf4a868faf8f2fe98b75973c223f8f10c\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.8.1-py3-none-any.whl size=19678 sha256=b24f5ff1c1d1d110b9aef92b71c2bf922fb3b37299be477d99442a4341d559bd\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/64/11/a5/143eba02bbc268191378c202be131d94b59ca40270bd49dd43\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=7c17055f7726198d8ce985a93b52738fde12d8d0e0b7f90a7ebeee05fc459dd8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.6.0-py3-none-any.whl size=92524 sha256=7ae18028aafb430625a1ccfdecd05df7c25b53508c2cc505c83f0a937b95e3a4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/25/2f/7c/d5c1cbcb535e30c90b88aa5104b1ee14a0ea9313a543bfdf52\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=a81725de78669edd6e70139edcf1913c56ca29698101a557ea162ebc9397d6fa\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=bb57b2f9c69c2b380208c025b3718eb287e5f99cf9e9f17261fbb2f445fde69e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built kfp docstring-parser fire kfp-server-api strip-hints termcolor\n",
      "Installing collected packages: termcolor, tabulate, strip-hints, requests-toolbelt, kubernetes, kfp-server-api, kfp-pipeline-spec, google-api-python-client, fire, docstring-parser, Deprecated, click, absl-py, kfp\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 17.17.0\n",
      "    Uninstalling kubernetes-17.17.0:\n",
      "      Successfully uninstalled kubernetes-17.17.0\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.9.0\n",
      "    Uninstalling google-api-python-client-2.9.0:\n",
      "      Successfully uninstalled google-api-python-client-2.9.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.1\n",
      "    Uninstalling click-8.0.1:\n",
      "      Successfully uninstalled click-8.0.1\n",
      "Successfully installed Deprecated-1.2.12 absl-py-0.11.0 click-7.1.2 docstring-parser-0.8.1 fire-0.4.0 google-api-python-client-1.12.8 kfp-1.6.4 kfp-pipeline-spec-0.1.8 kfp-server-api-1.6.0 kubernetes-12.0.1 requests-toolbelt-0.9.1 strip-hints-0.1.9 tabulate-0.8.9 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline/iris_training_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline/iris_training_pipeline.py\n",
    "\n",
    "\"\"\"KFP orchestrating BigQuery and Cloud AI Platform services.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from helper_components import evaluate_model\n",
    "from helper_components import retrieve_best_run\n",
    "from helper_components import custom_deploy\n",
    "from helper_components import prepoc_split_dataset\n",
    "from jinja2 import Template\n",
    "import kfp\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp.dsl.types import Dict\n",
    "from kfp.dsl.types import GCPProjectID\n",
    "from kfp.dsl.types import GCPRegion\n",
    "from kfp.dsl.types import GCSPath\n",
    "from kfp.dsl.types import String\n",
    "from kfp.gcp import use_gcp_secret\n",
    "\n",
    "# Defaults and environment settings\n",
    "BASE_IMAGE = os.getenv('BASE_IMAGE')\n",
    "TRAINER_IMAGE = os.getenv('TRAINER_IMAGE')\n",
    "RUNTIME_VERSION = os.getenv('RUNTIME_VERSION')\n",
    "PYTHON_VERSION = os.getenv('PYTHON_VERSION')\n",
    "COMPONENT_URL_SEARCH_PREFIX = os.getenv('COMPONENT_URL_SEARCH_PREFIX')\n",
    "USE_KFP_SA = os.getenv('USE_KFP_SA')\n",
    "\n",
    "TRAINING_FILE_PATH = 'datasets/training/data.csv'\n",
    "VALIDATION_FILE_PATH = 'datasets/validation/data.csv'\n",
    "TESTING_FILE_PATH = 'datasets/testing/data.csv'\n",
    "\n",
    "# Parameter defaults\n",
    "SPLITS_DATASET_ID = 'splits'\n",
    "HYPERTUNE_SETTINGS = \"\"\"\n",
    "{\n",
    "    \"hyperparameters\":  {\n",
    "        \"goal\": \"MAXIMIZE\",\n",
    "        \"maxTrials\": 6,\n",
    "        \"maxParallelTrials\": 3,\n",
    "        \"hyperparameterMetricTag\": \"accuracy\",\n",
    "        \"enableTrialEarlyStopping\": True,\n",
    "        \"params\": [\n",
    "            {\n",
    "                \"parameterName\": \"max_iter\",\n",
    "                \"type\": \"DISCRETE\",\n",
    "                \"discreteValues\": [90, 100]\n",
    "            },\n",
    "            {\n",
    "                \"parameterName\": \"alpha\",\n",
    "                \"type\": \"DOUBLE\",\n",
    "                \"minValue\": 0.001,\n",
    "                \"maxValue\": 0.004,\n",
    "                \"scaleType\": \"UNIT_LINEAR_SCALE\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create component factories\n",
    "component_store = kfp.components.ComponentStore(\n",
    "    local_search_paths=None, url_search_prefixes=[COMPONENT_URL_SEARCH_PREFIX])\n",
    "\n",
    "prepoc_split_op = func_to_container_op(prepoc_split_dataset, base_image=BASE_IMAGE)\n",
    "mlengine_train_op = component_store.load_component('ml_engine/train')\n",
    "mlengine_deploy_op = component_store.load_component('ml_engine/deploy')\n",
    "retrieve_best_run_op = func_to_container_op(\n",
    "    retrieve_best_run, base_image=BASE_IMAGE)\n",
    "evaluate_model_op = func_to_container_op(evaluate_model, base_image=BASE_IMAGE)\n",
    "custom_deploy_op = func_to_container_op(custom_deploy, base_image=BASE_IMAGE)\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name='Iris Classifier Training',\n",
    "    description='The pipeline training and deploying the Iris classifierpipeline_yaml'\n",
    ")\n",
    "def iris_train(project_id,\n",
    "                    region,\n",
    "                    gcs_root,\n",
    "                    dataset_id,\n",
    "                    evaluation_metric_name,\n",
    "                    evaluation_metric_threshold,\n",
    "                    model_id,\n",
    "                    version_id,\n",
    "                    replace_existing_version,\n",
    "                    hypertune_settings=HYPERTUNE_SETTINGS,\n",
    "                    dataset_location='US'):\n",
    "    \"\"\"Orchestrates training and deployment of an sklearn model.\"\"\"\n",
    "\n",
    "    splited_prepoc_dataset = prepoc_split_op(gcs_root)\n",
    "   \n",
    "    # Tune hyperparameters\n",
    "    tune_args = [\n",
    "        '--training_dataset_path',\n",
    "        splited_prepoc_dataset.outputs['training_file_path'],\n",
    "        '--validation_dataset_path',\n",
    "        splited_prepoc_dataset.outputs['validation_file_path'], '--hptune', 'True'\n",
    "    ]\n",
    "\n",
    "    job_dir = '{}/{}/{}'.format(gcs_root, 'jobdir/hypertune',\n",
    "                                kfp.dsl.RUN_ID_PLACEHOLDER)\n",
    "\n",
    "    hypertune = mlengine_train_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        master_image_uri=TRAINER_IMAGE,\n",
    "        job_dir=job_dir,\n",
    "        args=tune_args,\n",
    "        training_input=hypertune_settings)\n",
    "\n",
    "    # Retrieve the best trial\n",
    "    get_best_trial = retrieve_best_run_op(\n",
    "            project_id, hypertune.outputs['job_id'])\n",
    "\n",
    "    # Train the model on a combined training and validation datasets\n",
    "    job_dir = '{}/{}/{}'.format(gcs_root, 'jobdir', kfp.dsl.RUN_ID_PLACEHOLDER)\n",
    "\n",
    "    train_args = [\n",
    "        '--training_dataset_path',\n",
    "        splited_prepoc_dataset.outputs['training_file_path'],\n",
    "        '--validation_dataset_path',\n",
    "        splited_prepoc_dataset.outputs['validation_file_path'], '--alpha',\n",
    "        get_best_trial.outputs['alpha'], '--max_iter',\n",
    "        get_best_trial.outputs['max_iter'], '--hptune', 'False'\n",
    "    ]\n",
    "\n",
    "    train_model = mlengine_train_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        master_image_uri=TRAINER_IMAGE,\n",
    "        job_dir=job_dir,\n",
    "        args=train_args)\n",
    "\n",
    "    # Evaluate the model on the testing split\n",
    "    eval_model = evaluate_model_op(\n",
    "        testing_file_path=str(splited_prepoc_dataset.outputs['testing_file_path']),\n",
    "        model_path=str(train_model.outputs['job_dir']),\n",
    "        metric_name=evaluation_metric_name)\n",
    "\n",
    "    # Deploy the model if the primary metric is better than threshold\n",
    "    with kfp.dsl.Condition(eval_model.outputs['metric_value'] > evaluation_metric_threshold):\n",
    "        custom_deploy_op(\n",
    "        model_uri=str(train_model.outputs['job_dir']),\n",
    "        project_id=project_id,\n",
    "        model_id=model_id,\n",
    "        version_id=version_id)\n",
    "\n",
    "    # Configure the pipeline to run using the service account defined\n",
    "    # in the user-gcp-sa k8s secret\n",
    "    if USE_KFP_SA == 'True':\n",
    "        kfp.dsl.get_pipeline_conf().add_op_transformer(\n",
    "              use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.robotic-tide-284315.appspot.com/\n",
      "gs://robotic-tide-284315-kubeflowpipelines-default/\n",
      "gs://robotic-tide-284315_cloudbuild/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ENDPOINT = '74b539b8a4259f1d-dot-us-central1.pipelines.googleusercontent.com' # TO DO: REPLACE WITH YOUR ENDPOINT\n",
    "ARTIFACT_STORE_URI = 'gs://robotic-tide-284315-kubeflowpipelines-default'  # TO DO: REPLACE WITH YOUR ARTIFACT_STORE NAME \n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='trainer_image'\n",
    "TAG='latest'\n",
    "TRAINER_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 4 file(s) totalling 5.6 KiB before compression.\n",
      "Uploading tarball of [trainer_image] to [gs://robotic-tide-284315_cloudbuild/source/1626369533.646846-a1d36366220d47f48ef36ea716c804b1.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/robotic-tide-284315/locations/global/builds/254af586-c711-455b-b054-a59abef9d959].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/254af586-c711-455b-b054-a59abef9d959?project=678865744419].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"254af586-c711-455b-b054-a59abef9d959\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://robotic-tide-284315_cloudbuild/source/1626369533.646846-a1d36366220d47f48ef36ea716c804b1.tgz#1626369534027063\n",
      "Copying gs://robotic-tide-284315_cloudbuild/source/1626369533.646846-a1d36366220d47f48ef36ea716c804b1.tgz#1626369534027063...\n",
      "/ [1 files][  1.6 KiB/  1.6 KiB]                                                \n",
      "Operation completed over 1 objects/1.6 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  10.75kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "e7ae86ffe2df: Pulling fs layer\n",
      "a7a7ae3235b8: Pulling fs layer\n",
      "1400ccb64d82: Pulling fs layer\n",
      "6bf1e02be3ca: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "35497baed841: Pulling fs layer\n",
      "be8c2b483e14: Pulling fs layer\n",
      "5cc5ea0348cf: Pulling fs layer\n",
      "c66c267dbd8a: Pulling fs layer\n",
      "1a46d93947a8: Pulling fs layer\n",
      "3df3cc21a300: Pulling fs layer\n",
      "98990c035a71: Pulling fs layer\n",
      "582d3e1b0799: Pulling fs layer\n",
      "123a5c227305: Pulling fs layer\n",
      "e1a94bcd15d3: Pulling fs layer\n",
      "d25a1bbfe298: Pulling fs layer\n",
      "b00340de3e01: Pulling fs layer\n",
      "1a46d93947a8: Waiting\n",
      "6bf1e02be3ca: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "35497baed841: Waiting\n",
      "be8c2b483e14: Waiting\n",
      "c66c267dbd8a: Waiting\n",
      "5cc5ea0348cf: Waiting\n",
      "3df3cc21a300: Waiting\n",
      "98990c035a71: Waiting\n",
      "582d3e1b0799: Waiting\n",
      "123a5c227305: Waiting\n",
      "e1a94bcd15d3: Waiting\n",
      "d25a1bbfe298: Waiting\n",
      "b00340de3e01: Waiting\n",
      "a7a7ae3235b8: Verifying Checksum\n",
      "a7a7ae3235b8: Download complete\n",
      "e7ae86ffe2df: Verifying Checksum\n",
      "e7ae86ffe2df: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "35497baed841: Verifying Checksum\n",
      "35497baed841: Download complete\n",
      "6bf1e02be3ca: Verifying Checksum\n",
      "6bf1e02be3ca: Download complete\n",
      "5cc5ea0348cf: Verifying Checksum\n",
      "5cc5ea0348cf: Download complete\n",
      "c66c267dbd8a: Verifying Checksum\n",
      "c66c267dbd8a: Download complete\n",
      "1a46d93947a8: Verifying Checksum\n",
      "1a46d93947a8: Download complete\n",
      "3df3cc21a300: Verifying Checksum\n",
      "3df3cc21a300: Download complete\n",
      "98990c035a71: Verifying Checksum\n",
      "98990c035a71: Download complete\n",
      "582d3e1b0799: Verifying Checksum\n",
      "582d3e1b0799: Download complete\n",
      "123a5c227305: Verifying Checksum\n",
      "123a5c227305: Download complete\n",
      "e1a94bcd15d3: Verifying Checksum\n",
      "e1a94bcd15d3: Download complete\n",
      "be8c2b483e14: Verifying Checksum\n",
      "be8c2b483e14: Download complete\n",
      "b00340de3e01: Verifying Checksum\n",
      "b00340de3e01: Download complete\n",
      "1400ccb64d82: Verifying Checksum\n",
      "1400ccb64d82: Download complete\n",
      "e7ae86ffe2df: Pull complete\n",
      "a7a7ae3235b8: Pull complete\n",
      "d25a1bbfe298: Verifying Checksum\n",
      "d25a1bbfe298: Download complete\n",
      "1400ccb64d82: Pull complete\n",
      "6bf1e02be3ca: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "35497baed841: Pull complete\n",
      "be8c2b483e14: Pull complete\n",
      "5cc5ea0348cf: Pull complete\n",
      "c66c267dbd8a: Pull complete\n",
      "1a46d93947a8: Pull complete\n",
      "3df3cc21a300: Pull complete\n",
      "98990c035a71: Pull complete\n",
      "582d3e1b0799: Pull complete\n",
      "123a5c227305: Pull complete\n",
      "e1a94bcd15d3: Pull complete\n",
      "d25a1bbfe298: Pull complete\n",
      "b00340de3e01: Pull complete\n",
      "Digest: sha256:e45a8996ba986d5415f4a2570997df337fb3e6dee211ccec045f81ca710010d4\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> de178705f89d\n",
      "Step 2/5 : RUN pip install -U fire cloudml-hypertune scikit-learn==0.20.4 pandas==0.24.2\n",
      " ---> Running in fad8f9c32df5\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "Collecting scikit-learn==0.20.4\n",
      "  Downloading scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas==0.24.2) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: fire, cloudml-hypertune, termcolor\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=aabbf44bdc7ee5c1ec3dfe7946a5db28cbb08c8dfc13071600e8b8297152d3a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3988 sha256=009512e72d860d91d2952d87670237f3c71fe180e82febb571c212448e4074c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=47d463f1b0cfba28d39c972664feef409ee3363acce8297b28839484a35c9c5d\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built fire cloudml-hypertune termcolor\n",
      "Installing collected packages: termcolor, scikit-learn, pandas, fire, cloudml-hypertune\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.0\n",
      "    Uninstalling pandas-1.3.0:\n",
      "      Successfully uninstalled pandas-1.3.0\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6 fire-0.4.0 pandas-0.24.2 scikit-learn-0.20.4 termcolor-1.1.0\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "visions 0.7.1 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "phik 0.11.2 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "\u001b[0m\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container fad8f9c32df5\n",
      " ---> 61ba4ad8d923\n",
      "Step 3/5 : WORKDIR /app\n",
      " ---> Running in f3b0801b3fd5\n",
      "Removing intermediate container f3b0801b3fd5\n",
      " ---> cc9087982fd0\n",
      "Step 4/5 : COPY train.py .\n",
      " ---> bf3f5e236739\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 93e06f9a1472\n",
      "Removing intermediate container 93e06f9a1472\n",
      " ---> b814d7887bf9\n",
      "Successfully built b814d7887bf9\n",
      "Successfully tagged gcr.io/robotic-tide-284315/trainer_image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/robotic-tide-284315/trainer_image:latest\n",
      "The push refers to repository [gcr.io/robotic-tide-284315/trainer_image]\n",
      "7cd56862e8e1: Preparing\n",
      "1990c6bad73d: Preparing\n",
      "b53cce9467a2: Preparing\n",
      "612c2b874f71: Preparing\n",
      "58d4766f75b9: Preparing\n",
      "1ffa79ef958a: Preparing\n",
      "dd3641ae1300: Preparing\n",
      "048849384f76: Preparing\n",
      "60457308415e: Preparing\n",
      "a4d3edee0afb: Preparing\n",
      "dac3684feb38: Preparing\n",
      "bccf306961d3: Preparing\n",
      "9cc4461cdf50: Preparing\n",
      "c7f593b7df70: Preparing\n",
      "73b38e80b76b: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "5b89a247448d: Preparing\n",
      "a4eb0d67ce34: Preparing\n",
      "965a515811e3: Preparing\n",
      "878dab86cf0f: Preparing\n",
      "1ffa79ef958a: Waiting\n",
      "dd3641ae1300: Waiting\n",
      "048849384f76: Waiting\n",
      "60457308415e: Waiting\n",
      "a4d3edee0afb: Waiting\n",
      "dac3684feb38: Waiting\n",
      "bccf306961d3: Waiting\n",
      "9cc4461cdf50: Waiting\n",
      "c7f593b7df70: Waiting\n",
      "73b38e80b76b: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "5b89a247448d: Waiting\n",
      "a4eb0d67ce34: Waiting\n",
      "965a515811e3: Waiting\n",
      "878dab86cf0f: Waiting\n",
      "58d4766f75b9: Mounted from deeplearning-platform-release/base-cpu\n",
      "612c2b874f71: Mounted from deeplearning-platform-release/base-cpu\n",
      "1ffa79ef958a: Mounted from deeplearning-platform-release/base-cpu\n",
      "dd3641ae1300: Mounted from deeplearning-platform-release/base-cpu\n",
      "1990c6bad73d: Pushed\n",
      "7cd56862e8e1: Pushed\n",
      "048849384f76: Mounted from deeplearning-platform-release/base-cpu\n",
      "60457308415e: Mounted from deeplearning-platform-release/base-cpu\n",
      "dac3684feb38: Mounted from deeplearning-platform-release/base-cpu\n",
      "a4d3edee0afb: Mounted from deeplearning-platform-release/base-cpu\n",
      "bccf306961d3: Mounted from deeplearning-platform-release/base-cpu\n",
      "5f70bf18a086: Layer already exists\n",
      "c7f593b7df70: Mounted from deeplearning-platform-release/base-cpu\n",
      "9cc4461cdf50: Mounted from deeplearning-platform-release/base-cpu\n",
      "5b89a247448d: Mounted from deeplearning-platform-release/base-cpu\n",
      "73b38e80b76b: Mounted from deeplearning-platform-release/base-cpu\n",
      "a4eb0d67ce34: Mounted from deeplearning-platform-release/base-cpu\n",
      "965a515811e3: Mounted from deeplearning-platform-release/base-cpu\n",
      "878dab86cf0f: Layer already exists\n",
      "b53cce9467a2: Pushed\n",
      "latest: digest: sha256:4cb4d301d1e3d7c5f5b6b209322aab3d4df86b1ded0afce39ed328e6337bb8cb size: 4501\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                             IMAGES                                              STATUS\n",
      "254af586-c711-455b-b054-a59abef9d959  2021-07-15T17:18:54+00:00  2M58S     gs://robotic-tide-284315_cloudbuild/source/1626369533.646846-a1d36366220d47f48ef36ea716c804b1.tgz  gcr.io/robotic-tide-284315/trainer_image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TRAINER_IMAGE trainer_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='base_image'\n",
    "TAG='latest'\n",
    "BASE_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 244 bytes before compression.\n",
      "Uploading tarball of [base_image] to [gs://robotic-tide-284315_cloudbuild/source/1626363743.727561-09685699bdcc4c5ba9e537f6da00454a.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/robotic-tide-284315/locations/global/builds/f1d6279d-8481-4a5f-90a9-9c322098bdf2].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/f1d6279d-8481-4a5f-90a9-9c322098bdf2?project=678865744419].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"f1d6279d-8481-4a5f-90a9-9c322098bdf2\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://robotic-tide-284315_cloudbuild/source/1626363743.727561-09685699bdcc4c5ba9e537f6da00454a.tgz#1626363744072585\n",
      "Copying gs://robotic-tide-284315_cloudbuild/source/1626363743.727561-09685699bdcc4c5ba9e537f6da00454a.tgz#1626363744072585...\n",
      "/ [1 files][  284.0 B/  284.0 B]                                                \n",
      "Operation completed over 1 objects/284.0 B.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  3.584kB\n",
      "Step 1/2 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "25fa05cd42bd: Pulling fs layer\n",
      "334312f3cce5: Pulling fs layer\n",
      "69ae64a48940: Pulling fs layer\n",
      "fe5bbb0e39a4: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "80ddd5a9f1f3: Pulling fs layer\n",
      "76405ca8c0d7: Pulling fs layer\n",
      "96b547bd5851: Pulling fs layer\n",
      "165d356cc142: Pulling fs layer\n",
      "1f14d2578dc7: Pulling fs layer\n",
      "05c08f7ba2fb: Pulling fs layer\n",
      "b1c9ec7e36f6: Pulling fs layer\n",
      "94e3f0ba3fb3: Pulling fs layer\n",
      "00f212e657e4: Pulling fs layer\n",
      "7d32fad557e1: Pulling fs layer\n",
      "0024a6835488: Pulling fs layer\n",
      "a40f452ef7cf: Pulling fs layer\n",
      "fe5bbb0e39a4: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "80ddd5a9f1f3: Waiting\n",
      "76405ca8c0d7: Waiting\n",
      "96b547bd5851: Waiting\n",
      "165d356cc142: Waiting\n",
      "1f14d2578dc7: Waiting\n",
      "05c08f7ba2fb: Waiting\n",
      "b1c9ec7e36f6: Waiting\n",
      "94e3f0ba3fb3: Waiting\n",
      "00f212e657e4: Waiting\n",
      "7d32fad557e1: Waiting\n",
      "0024a6835488: Waiting\n",
      "a40f452ef7cf: Waiting\n",
      "334312f3cce5: Verifying Checksum\n",
      "334312f3cce5: Download complete\n",
      "25fa05cd42bd: Verifying Checksum\n",
      "25fa05cd42bd: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "80ddd5a9f1f3: Verifying Checksum\n",
      "80ddd5a9f1f3: Download complete\n",
      "fe5bbb0e39a4: Verifying Checksum\n",
      "fe5bbb0e39a4: Download complete\n",
      "96b547bd5851: Verifying Checksum\n",
      "96b547bd5851: Download complete\n",
      "165d356cc142: Download complete\n",
      "1f14d2578dc7: Verifying Checksum\n",
      "1f14d2578dc7: Download complete\n",
      "05c08f7ba2fb: Verifying Checksum\n",
      "05c08f7ba2fb: Download complete\n",
      "b1c9ec7e36f6: Verifying Checksum\n",
      "b1c9ec7e36f6: Download complete\n",
      "94e3f0ba3fb3: Verifying Checksum\n",
      "94e3f0ba3fb3: Download complete\n",
      "00f212e657e4: Verifying Checksum\n",
      "00f212e657e4: Download complete\n",
      "7d32fad557e1: Download complete\n",
      "76405ca8c0d7: Download complete\n",
      "a40f452ef7cf: Verifying Checksum\n",
      "a40f452ef7cf: Download complete\n",
      "69ae64a48940: Verifying Checksum\n",
      "69ae64a48940: Download complete\n",
      "25fa05cd42bd: Pull complete\n",
      "334312f3cce5: Pull complete\n",
      "0024a6835488: Verifying Checksum\n",
      "0024a6835488: Download complete\n",
      "69ae64a48940: Pull complete\n",
      "fe5bbb0e39a4: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "80ddd5a9f1f3: Pull complete\n",
      "76405ca8c0d7: Pull complete\n",
      "96b547bd5851: Pull complete\n",
      "165d356cc142: Pull complete\n",
      "1f14d2578dc7: Pull complete\n",
      "05c08f7ba2fb: Pull complete\n",
      "b1c9ec7e36f6: Pull complete\n",
      "94e3f0ba3fb3: Pull complete\n",
      "00f212e657e4: Pull complete\n",
      "7d32fad557e1: Pull complete\n",
      "0024a6835488: Pull complete\n",
      "a40f452ef7cf: Pull complete\n",
      "Digest: sha256:c3cba94690c7965f6561ebd38eeff7b0cc44b074df925d658afed5d6e9c7cf9d\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> 61dc917f58cf\n",
      "Step 2/2 : RUN pip install -U fire scikit-learn==0.20.4 pandas==0.24.2 kfp==0.2.5\n",
      " ---> Running in 59f03c774b9c\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "Collecting scikit-learn==0.20.4\n",
      "  Downloading scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting kfp==0.2.5\n",
      "  Downloading kfp-0.2.5.tar.gz (116 kB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2021.1)\n",
      "Collecting urllib3<1.25,>=1.15\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (2021.5.30)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (5.4.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (1.38.0)\n",
      "Collecting kubernetes<=10.0.0,>=8.0.0\n",
      "  Downloading kubernetes-10.0.0-py2.py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: PyJWT>=1.6.4 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (2.1.0)\n",
      "Requirement already satisfied: cryptography>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (3.4.7)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (1.30.2)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting cloudpickle==1.1.1\n",
      "  Downloading cloudpickle-1.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting kfp-server-api<=0.1.40,>=0.1.18\n",
      "  Downloading kfp-server-api-0.1.40.tar.gz (38 kB)\n",
      "Collecting argo-models==2.2.1a\n",
      "  Downloading argo-models-2.2.1a0.tar.gz (28 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.2.5) (3.2.0)\n",
      "Collecting tabulate==0.8.3\n",
      "  Downloading tabulate-0.8.3.tar.gz (46 kB)\n",
      "Collecting click==7.0\n",
      "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp==0.2.5) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=2.4.2->kfp==0.2.5) (2.20)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5) (49.6.0.post20210108)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.2.5) (4.2.2)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.2.5) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.2.5) (1.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.2.5) (2.25.1)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==0.2.5) (1.30.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==0.2.5) (3.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==0.2.5) (1.53.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==0.2.5) (20.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.2.5) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5) (4.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.2.5) (21.2.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<=10.0.0,>=8.0.0->kfp==0.2.5) (0.57.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<=10.0.0,>=8.0.0->kfp==0.2.5) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp==0.2.5) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==0.2.5) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==0.2.5) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp==0.2.5) (2.10)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated->kfp==0.2.5) (1.12.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp==0.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp==0.2.5) (3.10.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<=10.0.0,>=8.0.0->kfp==0.2.5) (3.1.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints->kfp==0.2.5) (0.36.2)\n",
      "Building wheels for collected packages: kfp, argo-models, tabulate, kfp-server-api, fire, strip-hints, termcolor\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-0.2.5-py3-none-any.whl size=159979 sha256=104e60e6197af1d502e7ae97eb212db4f88ce3fb69af0d8ca179f0f0f08a1a6b\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/74/7e/0a882d654bdf82d039460ab5c6adf8724ae56e277de7c0eaea\n",
      "  Building wheel for argo-models (setup.py): started\n",
      "  Building wheel for argo-models (setup.py): finished with status 'done'\n",
      "  Created wheel for argo-models: filename=argo_models-2.2.1a0-py3-none-any.whl size=57308 sha256=a06dc5d26f0abf5ad9d9fe98c3be4546f32e6196ae8843f2cb3dad17f7e211ae\n",
      "  Stored in directory: /root/.cache/pip/wheels/a9/4b/fd/cdd013bd2ad1a7162ecfaf954e9f1bb605174a20e3c02016b7\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23379 sha256=87972fc45cc1c79602f56cde238da986c763ec27f2b1f1990d4b6fd00ae391b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/a2/a6/812a8a9735b090913e109133c7c20aaca4cf07e8e18837714f\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-0.1.40-py3-none-any.whl size=102470 sha256=b3a4f2076f45fd7526deff58680d45eaeced83099815043379e7013f3ac70ba1\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/e3/43/3972dea76ee89e35f090b313817089043f2609236cf560069d\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=53af4c18ad3bef1aafed24d35be6f7bae8785b36f361edab773e5aece759a139\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=996a452e1b2d5d33ae7d11a119d86ebb43d86cfe7e074b35aa60488888b81d70\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=eb488e5b6cb95bccfcf758178a06179c86d67ffb106a5d08ac0c8ea3de09e4af\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built kfp argo-models tabulate kfp-server-api fire strip-hints termcolor\n",
      "Installing collected packages: urllib3, kubernetes, termcolor, tabulate, strip-hints, requests-toolbelt, kfp-server-api, Deprecated, cloudpickle, click, argo-models, scikit-learn, pandas, kfp, fire\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.5\n",
      "    Uninstalling urllib3-1.26.5:\n",
      "      Successfully uninstalled urllib3-1.26.5\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 17.17.0\n",
      "    Uninstalling kubernetes-17.17.0:\n",
      "      Successfully uninstalled kubernetes-17.17.0\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.6.0\n",
      "    Uninstalling cloudpickle-1.6.0:\n",
      "      Successfully uninstalled cloudpickle-1.6.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.1\n",
      "    Uninstalling click-8.0.1:\n",
      "      Successfully uninstalled click-8.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 4.9.2 requires ruamel_yaml>=0.11.14, which is not installed.\n",
      "visions 0.7.1 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "phik 0.11.2 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n",
      "pandas-profiling 3.0.0 requires pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "jupyterlab-git 0.11.0 requires nbdime<2.0.0,>=1.1.0, but you have nbdime 3.1.0 which is incompatible.\n",
      "black 21.5b2 requires click>=7.1.2, but you have click 7.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.12 argo-models-2.2.1a0 click-7.0 cloudpickle-1.1.1 fire-0.4.0 kfp-0.2.5 kfp-server-api-0.1.40 kubernetes-10.0.0 pandas-0.24.2 requests-toolbelt-0.9.1 scikit-learn-0.20.4 strip-hints-0.1.9 tabulate-0.8.3 termcolor-1.1.0 urllib3-1.24.3\n",
      "\u001b[91mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 59f03c774b9c\n",
      " ---> aece3be8fb61\n",
      "Successfully built aece3be8fb61\n",
      "Successfully tagged gcr.io/robotic-tide-284315/base_image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/robotic-tide-284315/base_image:latest\n",
      "The push refers to repository [gcr.io/robotic-tide-284315/base_image]\n",
      "c9d4dfe07579: Preparing\n",
      "8ab1d816881d: Preparing\n",
      "dc45e5046eba: Preparing\n",
      "29bf522d97b4: Preparing\n",
      "d96c519f0898: Preparing\n",
      "ff0a6aeeabc0: Preparing\n",
      "8a7cebfdebb3: Preparing\n",
      "c7b3d31e30d8: Preparing\n",
      "2bca48c23a02: Preparing\n",
      "e3772a518bda: Preparing\n",
      "89d9319acee8: Preparing\n",
      "3bcf6b758d7b: Preparing\n",
      "b07bdae450b2: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "844bb7de649e: Preparing\n",
      "e181fed681e9: Preparing\n",
      "e39414beba01: Preparing\n",
      "8f8f0266f834: Preparing\n",
      "ff0a6aeeabc0: Waiting\n",
      "c7b3d31e30d8: Waiting\n",
      "2bca48c23a02: Waiting\n",
      "e3772a518bda: Waiting\n",
      "89d9319acee8: Waiting\n",
      "3bcf6b758d7b: Waiting\n",
      "b07bdae450b2: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "844bb7de649e: Waiting\n",
      "e181fed681e9: Waiting\n",
      "e39414beba01: Waiting\n",
      "8f8f0266f834: Waiting\n",
      "8a7cebfdebb3: Waiting\n",
      "29bf522d97b4: Layer already exists\n",
      "8ab1d816881d: Layer already exists\n",
      "dc45e5046eba: Layer already exists\n",
      "d96c519f0898: Layer already exists\n",
      "8a7cebfdebb3: Layer already exists\n",
      "2bca48c23a02: Layer already exists\n",
      "c7b3d31e30d8: Layer already exists\n",
      "e3772a518bda: Layer already exists\n",
      "89d9319acee8: Layer already exists\n",
      "b07bdae450b2: Layer already exists\n",
      "3bcf6b758d7b: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "e39414beba01: Layer already exists\n",
      "e181fed681e9: Layer already exists\n",
      "844bb7de649e: Layer already exists\n",
      "8f8f0266f834: Layer already exists\n",
      "ff0a6aeeabc0: Layer already exists\n",
      "c9d4dfe07579: Pushed\n",
      "latest: digest: sha256:d40adbbf273d3fb5b031fbfc2aa58eda2529cc4a92a86680bc99d7ca9a5cc978 size: 4085\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                             IMAGES                                           STATUS\n",
      "f1d6279d-8481-4a5f-90a9-9c322098bdf2  2021-07-15T15:42:24+00:00  3M5S      gs://robotic-tide-284315_cloudbuild/source/1626363743.727561-09685699bdcc4c5ba9e537f6da00454a.tgz  gcr.io/robotic-tide-284315/base_image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $BASE_IMAGE base_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_KFP_SA=False\n",
      "env: BASE_IMAGE=gcr.io/robotic-tide-284315/base_image:latest\n",
      "env: TRAINER_IMAGE=gcr.io/robotic-tide-284315/trainer_image:latest\n",
      "env: COMPONENT_URL_SEARCH_PREFIX=https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/\n",
      "env: RUNTIME_VERSION=1.15\n",
      "env: PYTHON_VERSION=3.7\n"
     ]
    }
   ],
   "source": [
    "USE_KFP_SA = False\n",
    "\n",
    "COMPONENT_URL_SEARCH_PREFIX = 'https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/'\n",
    "RUNTIME_VERSION = '1.15'\n",
    "PYTHON_VERSION = '3.7'\n",
    "\n",
    "%env USE_KFP_SA={USE_KFP_SA}\n",
    "%env BASE_IMAGE={BASE_IMAGE}\n",
    "%env TRAINER_IMAGE={TRAINER_IMAGE}\n",
    "%env COMPONENT_URL_SEARCH_PREFIX={COMPONENT_URL_SEARCH_PREFIX}\n",
    "%env RUNTIME_VERSION={RUNTIME_VERSION}\n",
    "%env PYTHON_VERSION={PYTHON_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the pipeline package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dsl-compile --py pipeline/iris_training_pipeline.py --output iris_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 74b539b8a4259f1d-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "Pipeline Details\n",
      "------------------\n",
      "ID           7b6732b9-0d5f-4ae5-bc8e-c3ea0efd6cab\n",
      "Name         iris_continuous_training_v3\n",
      "Description\n",
      "Uploaded at  2021-07-15T21:37:42+00:00\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| Parameter Name              | Default Value                                    |\n",
      "+=============================+==================================================+\n",
      "| project_id                  |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| region                      |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| gcs_root                    |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| dataset_id                  |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| evaluation_metric_name      |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| evaluation_metric_threshold |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| model_id                    |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| version_id                  |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| replace_existing_version    |                                                  |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| hypertune_settings          | {                                                |\n",
      "|                             |     \"hyperparameters\":  {                        |\n",
      "|                             |         \"goal\": \"MAXIMIZE\",                      |\n",
      "|                             |         \"maxTrials\": 6,                          |\n",
      "|                             |         \"maxParallelTrials\": 3,                  |\n",
      "|                             |         \"hyperparameterMetricTag\": \"accuracy\",   |\n",
      "|                             |         \"enableTrialEarlyStopping\": True,        |\n",
      "|                             |         \"params\": [                              |\n",
      "|                             |             {                                    |\n",
      "|                             |                 \"parameterName\": \"max_iter\",     |\n",
      "|                             |                 \"type\": \"DISCRETE\",              |\n",
      "|                             |                 \"discreteValues\": [90, 100]      |\n",
      "|                             |             },                                   |\n",
      "|                             |             {                                    |\n",
      "|                             |                 \"parameterName\": \"alpha\",        |\n",
      "|                             |                 \"type\": \"DOUBLE\",                |\n",
      "|                             |                 \"minValue\": 0.001,               |\n",
      "|                             |                 \"maxValue\": 0.004,               |\n",
      "|                             |                 \"scaleType\": \"UNIT_LINEAR_SCALE\" |\n",
      "|                             |             }                                    |\n",
      "|                             |         ]                                        |\n",
      "|                             |     }                                            |\n",
      "|                             | }                                                |\n",
      "+-----------------------------+--------------------------------------------------+\n",
      "| dataset_location            | US                                               |\n",
      "+-----------------------------+--------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME='iris_continuous_training_v3'\n",
    "\n",
    "!kfp --endpoint $ENDPOINT pipeline upload \\\n",
    "-p $PIPELINE_NAME \\\n",
    "iris_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 74b539b8a4259f1d-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| Pipeline ID                          | Name                                           | Uploaded at               |\n",
      "+======================================+================================================+===========================+\n",
      "| 7b6732b9-0d5f-4ae5-bc8e-c3ea0efd6cab | iris_continuous_training_v3                    | 2021-07-15T21:37:42+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 70199f59-dbd2-4777-88fc-f489324df6dd | iris_continuous_training_v2                    | 2021-07-15T21:06:11+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 9d56fc8c-34d4-4f00-8049-72ab9b478db9 | iris_continuous_training_v1                    | 2021-07-15T20:40:49+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 888e1937-d153-4e82-84d5-9cc85145e50f | iris_continuous_training                       | 2021-07-15T20:13:34+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 59018aa6-2775-4f76-a5f2-cf92162e3685 | iris_continuous_training_v12                   | 2021-07-15T18:20:29+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| e67112e2-1d53-4c5a-9309-cda80b0e4a53 | [Tutorial] DSL - Control structures            | 2021-07-15T13:50:46+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 74181b6c-6c8c-4872-9ca0-95257e3602c4 | [Tutorial] Data passing in python components   | 2021-07-15T13:50:45+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| ff3dfd5b-ba52-4492-b10d-d3f572933c4d | [Demo] TFX - Taxi tip prediction model trainer | 2021-07-15T13:50:44+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n",
      "| 6d8e2372-4481-4049-9390-5265766f1954 | [Demo] XGBoost - Iterative model training      | 2021-07-15T13:50:43+00:00 |\n",
      "+--------------------------------------+------------------------------------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT pipeline list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ID='7b6732b9-0d5f-4ae5-bc8e-c3ea0efd6cab' # TO DO: REPLACE WITH YOUR PIPELINE ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Iris_Classifier_Training'\n",
    "RUN_ID = 'Run_001'\n",
    "DATASET_ID = 'splits'\n",
    "EVALUATION_METRIC = 'accuracy'\n",
    "EVALUATION_METRIC_THRESHOLD = '0.69'\n",
    "MODEL_ID = 'iris_classifier'\n",
    "VERSION_ID = 'v01'\n",
    "REPLACE_EXISTING_VERSION = 'True'\n",
    "\n",
    "GCS_STAGING_PATH = '{}/staging'.format(ARTIFACT_STORE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 74b539b8a4259f1d-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "+--------------------------------------+---------+----------+---------------------------+\n",
      "| run id                               | name    | status   | created at                |\n",
      "+======================================+=========+==========+===========================+\n",
      "| ed322b00-6e5c-407e-b667-b0a21ffbf451 | Run_001 |          | 2021-07-15T21:38:12+00:00 |\n",
      "+--------------------------------------+---------+----------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT run submit \\\n",
    "-e $EXPERIMENT_NAME \\\n",
    "-r $RUN_ID \\\n",
    "-p $PIPELINE_ID \\\n",
    "project_id=$PROJECT_ID \\\n",
    "gcs_root=$GCS_STAGING_PATH \\\n",
    "region=$REGION \\\n",
    "dataset_id=$DATASET_ID \\\n",
    "evaluation_metric_name=$EVALUATION_METRIC \\\n",
    "evaluation_metric_threshold=$EVALUATION_METRIC_THRESHOLD \\\n",
    "model_id=$MODEL_ID \\\n",
    "version_id=$VERSION_ID \\\n",
    "replace_existing_version=$REPLACE_EXISTING_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74b539b8a4259f1d-dot-us-central1.pipelines.googleusercontent.com\n"
     ]
    }
   ],
   "source": [
    "!echo $ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
