apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: iris-classifier-training-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline_compilation_time: '2021-07-15T21:37:34.452798',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "The pipeline training
      and deploying the Iris classifierpipeline_yaml", "inputs": [{"name": "project_id"},
      {"name": "region"}, {"name": "gcs_root"}, {"name": "dataset_id"}, {"name": "evaluation_metric_name"},
      {"name": "evaluation_metric_threshold"}, {"name": "model_id"}, {"name": "version_id"},
      {"name": "replace_existing_version"}, {"default": "\n{\n    \"hyperparameters\":  {\n        \"goal\":
      \"MAXIMIZE\",\n        \"maxTrials\": 6,\n        \"maxParallelTrials\": 3,\n        \"hyperparameterMetricTag\":
      \"accuracy\",\n        \"enableTrialEarlyStopping\": True,\n        \"params\":
      [\n            {\n                \"parameterName\": \"max_iter\",\n                \"type\":
      \"DISCRETE\",\n                \"discreteValues\": [90, 100]\n            },\n            {\n                \"parameterName\":
      \"alpha\",\n                \"type\": \"DOUBLE\",\n                \"minValue\":
      0.001,\n                \"maxValue\": 0.004,\n                \"scaleType\":
      \"UNIT_LINEAR_SCALE\"\n            }\n        ]\n    }\n}\n", "name": "hypertune_settings",
      "optional": true}, {"default": "US", "name": "dataset_location", "optional":
      true}], "name": "Iris Classifier Training"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4}
spec:
  entrypoint: iris-classifier-training
  templates:
  - name: condition-1
    inputs:
      parameters:
      - {name: model_id}
      - {name: project_id}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
      - {name: version_id}
    dag:
      tasks:
      - name: custom-deploy
        template: custom-deploy
        arguments:
          parameters:
          - {name: model_id, value: '{{inputs.parameters.model_id}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
          - {name: version_id, value: '{{inputs.parameters.version_id}}'}
  - name: custom-deploy
    container:
      args: [--model-uri, '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}',
        --project-id, '{{inputs.parameters.project_id}}', --model-id, '{{inputs.parameters.model_id}}',
        --version-id, '{{inputs.parameters.version_id}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def custom_deploy(model_uri, project_id,model_id,version_id):
          import subprocess
          import sys

          model_filename = 'model.pkl'
          gcs_model_filepath = '{}/{}'.format(model_uri, model_filename)
          print(gcs_model_filepath)
          subprocess.check_call(['gsutil', 'cp', gcs_model_filepath, 'deployApi/{}'.format(model_filename)],
                                stderr=sys.stdout)
          subprocess.check_call(['gcloud', 'builds', 'submit', '--config', 'deployApi/cloudbuild.yaml',
                    '--substitutions', '_PROJECT_ID={},_API_NAME={},_VERSION={}'.format(project_id,model_id,version_id)] ,stderr=sys.stdout)

          subprocess.check_call(['gsutil', 'run', 'deploy', model_id, '--image gcr.io/{}/{}:{}'.format(project_id,model_id,version_id)],
                                stderr=sys.stdout)

        import argparse
        _parser = argparse.ArgumentParser(prog='Custom deploy', description='')
        _parser.add_argument("--model-uri", dest="model_uri", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--project-id", dest="project_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model-id", dest="model_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--version-id", dest="version_id", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = custom_deploy(**_parsed_args)
      image: gcr.io/robotic-tide-284315/base_image:latest
    inputs:
      parameters:
      - {name: model_id}
      - {name: project_id}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
      - {name: version_id}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--model-uri", {"inputValue": "model_uri"}, "--project-id", {"inputValue":
          "project_id"}, "--model-id", {"inputValue": "model_id"}, "--version-id",
          {"inputValue": "version_id"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def custom_deploy(model_uri, project_id,model_id,version_id):\n  import
          subprocess\n  import sys\n\n  model_filename = ''model.pkl''\n  gcs_model_filepath
          = ''{}/{}''.format(model_uri, model_filename)\n  print(gcs_model_filepath)\n  subprocess.check_call([''gsutil'',
          ''cp'', gcs_model_filepath, ''deployApi/{}''.format(model_filename)],\n                        stderr=sys.stdout)\n  subprocess.check_call([''gcloud'',
          ''builds'', ''submit'', ''--config'', ''deployApi/cloudbuild.yaml'',\n            ''--substitutions'',
          ''_PROJECT_ID={},_API_NAME={},_VERSION={}''.format(project_id,model_id,version_id)]
          ,stderr=sys.stdout)\n\n  subprocess.check_call([''gsutil'', ''run'', ''deploy'',
          model_id, ''--image gcr.io/{}/{}:{}''.format(project_id,model_id,version_id)],\n                        stderr=sys.stdout)\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Custom deploy'', description='''')\n_parser.add_argument(\"--model-uri\",
          dest=\"model_uri\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--project-id\",
          dest=\"project_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-id\",
          dest=\"model_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--version-id\",
          dest=\"version_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = custom_deploy(**_parsed_args)\n"],
          "image": "gcr.io/robotic-tide-284315/base_image:latest"}}, "inputs": [{"name":
          "model_uri", "type": "String"}, {"name": "project_id", "type": "String"},
          {"name": "model_id", "type": "String"}, {"name": "version_id", "type": "String"}],
          "name": "Custom deploy"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"model_id":
          "{{inputs.parameters.model_id}}", "model_uri": "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}",
          "project_id": "{{inputs.parameters.project_id}}", "version_id": "{{inputs.parameters.version_id}}"}'}
  - name: evaluate-model
    container:
      args: [--testing-file-path, '{{inputs.parameters.prepoc-split-dataset-testing_file_path}}',
        --model-path, '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}',
        --metric-name, '{{inputs.parameters.evaluation_metric_name}}', '----output-paths',
        /tmp/outputs/metric_name/data, /tmp/outputs/metric_value/data, /tmp/outputs/mlpipeline_metrics/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def evaluate_model(
            testing_file_path, model_path, metric_name
        ):
          """Evaluates a trained sklearn model."""
          #import joblib
          import pickle
          import json
          import pandas as pd
          import subprocess
          import sys

          from sklearn.metrics import accuracy_score, recall_score

          df_test = pd.read_csv(testing_file_path)

          X_test = df_test.drop('classEncoder', axis=1)
          y_test = df_test['classEncoder']

          # Copy the model from GCS
          model_filename = 'model.pkl'
          gcs_model_filepath = '{}/{}'.format(model_path, model_filename)
          print(gcs_model_filepath)
          subprocess.check_call(['gsutil', 'cp', gcs_model_filepath, model_filename],
                                stderr=sys.stdout)

          with open(model_filename, 'rb') as model_file:
            model = pickle.load(model_file)

          y_hat = model.predict(X_test)

          if metric_name == 'accuracy':
            metric_value = accuracy_score(y_test, y_hat)
          elif metric_name == 'recall':
            metric_value = recall_score(y_test, y_hat)
          else:
            metric_name = 'N/A'
            metric_value = 0

          # Export the metric
          metrics = {
              'metrics': [{
                  'name': metric_name,
                  'numberValue': float(metric_value)
              }]
          }

          return (metric_name, metric_value, json.dumps(metrics))

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Evaluate model', description='Evaluates a trained sklearn model.')
        _parser.add_argument("--testing-file-path", dest="testing_file_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--model-path", dest="model_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--metric-name", dest="metric_name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = evaluate_model(**_parsed_args)

        _output_serializers = [
            _serialize_str,
            _serialize_float,
            str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: gcr.io/robotic-tide-284315/base_image:latest
    inputs:
      parameters:
      - {name: evaluation_metric_name}
      - {name: prepoc-split-dataset-testing_file_path}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}
    outputs:
      parameters:
      - name: evaluate-model-metric_value
        valueFrom: {path: /tmp/outputs/metric_value/data}
      artifacts:
      - {name: mlpipeline-metrics, path: /tmp/outputs/mlpipeline_metrics/data}
      - {name: evaluate-model-metric_name, path: /tmp/outputs/metric_name/data}
      - {name: evaluate-model-metric_value, path: /tmp/outputs/metric_value/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Evaluates
          a trained sklearn model.", "implementation": {"container": {"args": ["--testing-file-path",
          {"inputValue": "testing_file_path"}, "--model-path", {"inputValue": "model_path"},
          "--metric-name", {"inputValue": "metric_name"}, "----output-paths", {"outputPath":
          "metric_name"}, {"outputPath": "metric_value"}, {"outputPath": "mlpipeline_metrics"}],
          "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" >
          \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def evaluate_model(\n    testing_file_path,
          model_path, metric_name\n):\n  \"\"\"Evaluates a trained sklearn model.\"\"\"\n  #import
          joblib\n  import pickle\n  import json\n  import pandas as pd\n  import
          subprocess\n  import sys\n\n  from sklearn.metrics import accuracy_score,
          recall_score\n\n  df_test = pd.read_csv(testing_file_path)\n\n  X_test =
          df_test.drop(''classEncoder'', axis=1)\n  y_test = df_test[''classEncoder'']\n\n  #
          Copy the model from GCS\n  model_filename = ''model.pkl''\n  gcs_model_filepath
          = ''{}/{}''.format(model_path, model_filename)\n  print(gcs_model_filepath)\n  subprocess.check_call([''gsutil'',
          ''cp'', gcs_model_filepath, model_filename],\n                        stderr=sys.stdout)\n\n  with
          open(model_filename, ''rb'') as model_file:\n    model = pickle.load(model_file)\n\n  y_hat
          = model.predict(X_test)\n\n  if metric_name == ''accuracy'':\n    metric_value
          = accuracy_score(y_test, y_hat)\n  elif metric_name == ''recall'':\n    metric_value
          = recall_score(y_test, y_hat)\n  else:\n    metric_name = ''N/A''\n    metric_value
          = 0\n\n  # Export the metric\n  metrics = {\n      ''metrics'': [{\n          ''name'':
          metric_name,\n          ''numberValue'': float(metric_value)\n      }]\n  }\n\n  return
          (metric_name, metric_value, json.dumps(metrics))\n\ndef _serialize_float(float_value:
          float) -> str:\n    if isinstance(float_value, str):\n        return float_value\n    if
          not isinstance(float_value, (float, int)):\n        raise TypeError(''Value
          \"{}\" has type \"{}\" instead of float.''.format(str(float_value), str(type(float_value))))\n    return
          str(float_value)\n\ndef _serialize_str(str_value: str) -> str:\n    if not
          isinstance(str_value, str):\n        raise TypeError(''Value \"{}\" has
          type \"{}\" instead of str.''.format(str(str_value), str(type(str_value))))\n    return
          str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Evaluate
          model'', description=''Evaluates a trained sklearn model.'')\n_parser.add_argument(\"--testing-file-path\",
          dest=\"testing_file_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--model-path\",
          dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--metric-name\",
          dest=\"metric_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=3)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = evaluate_model(**_parsed_args)\n\n_output_serializers
          = [\n    _serialize_str,\n    _serialize_float,\n    str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "gcr.io/robotic-tide-284315/base_image:latest"}}, "inputs": [{"name":
          "testing_file_path", "type": "String"}, {"name": "model_path", "type": "String"},
          {"name": "metric_name", "type": "String"}], "name": "Evaluate model", "outputs":
          [{"name": "metric_name", "type": "String"}, {"name": "metric_value", "type":
          "Float"}, {"name": "mlpipeline_metrics", "type": "Metrics"}]}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"metric_name": "{{inputs.parameters.evaluation_metric_name}}",
          "model_path": "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}",
          "testing_file_path": "{{inputs.parameters.prepoc-split-dataset-testing_file_path}}"}'}
  - name: iris-classifier-training
    inputs:
      parameters:
      - {name: evaluation_metric_name}
      - {name: evaluation_metric_threshold}
      - {name: gcs_root}
      - {name: hypertune_settings}
      - {name: model_id}
      - {name: project_id}
      - {name: region}
      - {name: version_id}
    dag:
      tasks:
      - name: condition-1
        template: condition-1
        when: '{{tasks.evaluate-model.outputs.parameters.evaluate-model-metric_value}}
          > {{inputs.parameters.evaluation_metric_threshold}}'
        dependencies: [evaluate-model, submitting-a-cloud-ml-training-job-as-a-pipeline-step-2]
        arguments:
          parameters:
          - {name: model_id, value: '{{inputs.parameters.model_id}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
          - {name: version_id, value: '{{inputs.parameters.version_id}}'}
      - name: evaluate-model
        template: evaluate-model
        dependencies: [prepoc-split-dataset, submitting-a-cloud-ml-training-job-as-a-pipeline-step-2]
        arguments:
          parameters:
          - {name: evaluation_metric_name, value: '{{inputs.parameters.evaluation_metric_name}}'}
          - {name: prepoc-split-dataset-testing_file_path, value: '{{tasks.prepoc-split-dataset.outputs.parameters.prepoc-split-dataset-testing_file_path}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir,
            value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir}}'}
      - name: prepoc-split-dataset
        template: prepoc-split-dataset
        arguments:
          parameters:
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
      - name: retrieve-best-run
        template: retrieve-best-run
        dependencies: [submitting-a-cloud-ml-training-job-as-a-pipeline-step]
        arguments:
          parameters:
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id, value: '{{tasks.submitting-a-cloud-ml-training-job-as-a-pipeline-step.outputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}'}
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step
        template: submitting-a-cloud-ml-training-job-as-a-pipeline-step
        dependencies: [prepoc-split-dataset]
        arguments:
          parameters:
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: hypertune_settings, value: '{{inputs.parameters.hypertune_settings}}'}
          - {name: prepoc-split-dataset-training_file_path, value: '{{tasks.prepoc-split-dataset.outputs.parameters.prepoc-split-dataset-training_file_path}}'}
          - {name: prepoc-split-dataset-validation_file_path, value: '{{tasks.prepoc-split-dataset.outputs.parameters.prepoc-split-dataset-validation_file_path}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: region, value: '{{inputs.parameters.region}}'}
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        template: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
        dependencies: [prepoc-split-dataset, retrieve-best-run]
        arguments:
          parameters:
          - {name: gcs_root, value: '{{inputs.parameters.gcs_root}}'}
          - {name: prepoc-split-dataset-training_file_path, value: '{{tasks.prepoc-split-dataset.outputs.parameters.prepoc-split-dataset-training_file_path}}'}
          - {name: prepoc-split-dataset-validation_file_path, value: '{{tasks.prepoc-split-dataset.outputs.parameters.prepoc-split-dataset-validation_file_path}}'}
          - {name: project_id, value: '{{inputs.parameters.project_id}}'}
          - {name: region, value: '{{inputs.parameters.region}}'}
          - {name: retrieve-best-run-alpha, value: '{{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-alpha}}'}
          - {name: retrieve-best-run-max_iter, value: '{{tasks.retrieve-best-run.outputs.parameters.retrieve-best-run-max_iter}}'}
  - name: prepoc-split-dataset
    container:
      args: [--root-path, '{{inputs.parameters.gcs_root}}', '----output-paths', /tmp/outputs/training_file_path/data,
        /tmp/outputs/validation_file_path/data, /tmp/outputs/testing_file_path/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def prepoc_split_dataset(root_path
        ):

          import pandas as pd
          from sklearn.model_selection import train_test_split
          from sklearn import preprocessing
          import os

          os.system('curl -o iris.txt  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')

          os.system('gsutil cp  iris.txt  {}'.format(root_path))

          columns = ['sepal_length','sepal_width','petal_length','petal_width','class']

          dfIris = pd.read_csv('{}/iris.txt'.format(root_path), names=columns)
          le = preprocessing.LabelEncoder()
          dfIris['classEncoder'] = le.fit_transform(dfIris['class'])

          X_train, X_val_test, y_train, y_val_test = train_test_split(dfIris.drop(['classEncoder','class'], axis=1), dfIris['classEncoder'], test_size=0.2)

          X_val, X_test, y_val, y_test = train_test_split(X_val_test,y_val_test, test_size=0.5)

          df_train = pd.concat([X_train,y_train],axis=1)
          df_val = pd.concat([X_val,y_val],axis=1)
          df_test = pd.concat([X_test,y_test],axis=1)

          df_train.to_csv('train.txt', index=False)
          df_val.to_csv('validation.txt', index=False)
          df_test.to_csv('test.txt' , index=False)

          os.system('gsutil cp  train.txt  {}'.format(root_path))
          os.system('gsutil cp  validation.txt  {}'.format(root_path))
          os.system('gsutil cp  test.txt  {}'.format(root_path))

          training_file_path = '{}/train.txt'.format(root_path)
          validation_file_path = '{}/validation.txt'.format(root_path)
          testing_file_path = '{}/test.txt'.format(root_path)

          return (training_file_path,validation_file_path,testing_file_path)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Prepoc split dataset', description='')
        _parser.add_argument("--root-path", dest="root_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = prepoc_split_dataset(**_parsed_args)

        _output_serializers = [
            _serialize_str,
            _serialize_str,
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: gcr.io/robotic-tide-284315/base_image:latest
    inputs:
      parameters:
      - {name: gcs_root}
    outputs:
      parameters:
      - name: prepoc-split-dataset-testing_file_path
        valueFrom: {path: /tmp/outputs/testing_file_path/data}
      - name: prepoc-split-dataset-training_file_path
        valueFrom: {path: /tmp/outputs/training_file_path/data}
      - name: prepoc-split-dataset-validation_file_path
        valueFrom: {path: /tmp/outputs/validation_file_path/data}
      artifacts:
      - {name: prepoc-split-dataset-testing_file_path, path: /tmp/outputs/testing_file_path/data}
      - {name: prepoc-split-dataset-training_file_path, path: /tmp/outputs/training_file_path/data}
      - {name: prepoc-split-dataset-validation_file_path, path: /tmp/outputs/validation_file_path/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--root-path", {"inputValue": "root_path"}, "----output-paths",
          {"outputPath": "training_file_path"}, {"outputPath": "validation_file_path"},
          {"outputPath": "testing_file_path"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def prepoc_split_dataset(root_path\n):\n\n  import pandas as pd\n  from
          sklearn.model_selection import train_test_split\n  from sklearn import preprocessing\n  import
          os\n\n  os.system(''curl -o iris.txt  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'')\n\n  os.system(''gsutil
          cp  iris.txt  {}''.format(root_path))\n\n  columns = [''sepal_length'',''sepal_width'',''petal_length'',''petal_width'',''class'']\n\n  dfIris
          = pd.read_csv(''{}/iris.txt''.format(root_path), names=columns)\n  le =
          preprocessing.LabelEncoder()\n  dfIris[''classEncoder''] = le.fit_transform(dfIris[''class''])\n\n  X_train,
          X_val_test, y_train, y_val_test = train_test_split(dfIris.drop([''classEncoder'',''class''],
          axis=1), dfIris[''classEncoder''], test_size=0.2)\n\n  X_val, X_test, y_val,
          y_test = train_test_split(X_val_test,y_val_test, test_size=0.5)\n\n  df_train
          = pd.concat([X_train,y_train],axis=1)\n  df_val = pd.concat([X_val,y_val],axis=1)\n  df_test
          = pd.concat([X_test,y_test],axis=1)\n\n  df_train.to_csv(''train.txt'',
          index=False)\n  df_val.to_csv(''validation.txt'', index=False)\n  df_test.to_csv(''test.txt''
          , index=False)\n\n  os.system(''gsutil cp  train.txt  {}''.format(root_path))\n  os.system(''gsutil
          cp  validation.txt  {}''.format(root_path))\n  os.system(''gsutil cp  test.txt  {}''.format(root_path))\n\n  training_file_path
          = ''{}/train.txt''.format(root_path)\n  validation_file_path = ''{}/validation.txt''.format(root_path)\n  testing_file_path
          = ''{}/test.txt''.format(root_path)\n\n  return (training_file_path,validation_file_path,testing_file_path)\n\ndef
          _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,
          str):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead of
          str.''.format(str(str_value), str(type(str_value))))\n    return str_value\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Prepoc split dataset'',
          description='''')\n_parser.add_argument(\"--root-path\", dest=\"root_path\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=3)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = prepoc_split_dataset(**_parsed_args)\n\n_output_serializers
          = [\n    _serialize_str,\n    _serialize_str,\n    _serialize_str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "gcr.io/robotic-tide-284315/base_image:latest"}}, "inputs": [{"name":
          "root_path", "type": "String"}], "name": "Prepoc split dataset", "outputs":
          [{"name": "training_file_path", "type": "String"}, {"name": "validation_file_path",
          "type": "String"}, {"name": "testing_file_path", "type": "String"}]}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"root_path": "{{inputs.parameters.gcs_root}}"}'}
  - name: retrieve-best-run
    container:
      args: [--project-id, '{{inputs.parameters.project_id}}', --job-id, '{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}',
        '----output-paths', /tmp/outputs/metric_value/data, /tmp/outputs/alpha/data,
        /tmp/outputs/max_iter/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def retrieve_best_run(
            project_id, job_id
        ):
          """Retrieves the parameters of the best Hypertune run."""

          from googleapiclient import discovery
          from googleapiclient import errors

          ml = discovery.build('ml', 'v1')

          job_name = 'projects/{}/jobs/{}'.format(project_id, job_id)
          request = ml.projects().jobs().get(name=job_name)

          try:
            response = request.execute()
          except errors.HttpError as err:
            print(err)
          except:
            print('Unexpected error')

          print(response)

          best_trial = response['trainingOutput']['trials'][0]

          metric_value = best_trial['finalMetric']['objectiveValue']
          alpha = float(best_trial['hyperparameters']['alpha'])
          max_iter = int(best_trial['hyperparameters']['max_iter'])

          return (metric_value, alpha, max_iter)

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(str(float_value), str(type(float_value))))
            return str(float_value)

        def _serialize_int(int_value: int) -> str:
            if isinstance(int_value, str):
                return int_value
            if not isinstance(int_value, int):
                raise TypeError('Value "{}" has type "{}" instead of int.'.format(str(int_value), str(type(int_value))))
            return str(int_value)

        import argparse
        _parser = argparse.ArgumentParser(prog='Retrieve best run', description='Retrieves the parameters of the best Hypertune run.')
        _parser.add_argument("--project-id", dest="project_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--job-id", dest="job_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = retrieve_best_run(**_parsed_args)

        _output_serializers = [
            _serialize_float,
            _serialize_float,
            _serialize_int,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: gcr.io/robotic-tide-284315/base_image:latest
    inputs:
      parameters:
      - {name: project_id}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}
    outputs:
      parameters:
      - name: retrieve-best-run-alpha
        valueFrom: {path: /tmp/outputs/alpha/data}
      - name: retrieve-best-run-max_iter
        valueFrom: {path: /tmp/outputs/max_iter/data}
      artifacts:
      - {name: retrieve-best-run-alpha, path: /tmp/outputs/alpha/data}
      - {name: retrieve-best-run-max_iter, path: /tmp/outputs/max_iter/data}
      - {name: retrieve-best-run-metric_value, path: /tmp/outputs/metric_value/data}
    metadata:
      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.6.4, pipelines.kubeflow.org/pipeline-sdk-type: kfp}
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Retrieves
          the parameters of the best Hypertune run.", "implementation": {"container":
          {"args": ["--project-id", {"inputValue": "project_id"}, "--job-id", {"inputValue":
          "job_id"}, "----output-paths", {"outputPath": "metric_value"}, {"outputPath":
          "alpha"}, {"outputPath": "max_iter"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def retrieve_best_run(\n    project_id, job_id\n):\n  \"\"\"Retrieves the
          parameters of the best Hypertune run.\"\"\"\n\n  from googleapiclient import
          discovery\n  from googleapiclient import errors\n\n  ml = discovery.build(''ml'',
          ''v1'')\n\n  job_name = ''projects/{}/jobs/{}''.format(project_id, job_id)\n  request
          = ml.projects().jobs().get(name=job_name)\n\n  try:\n    response = request.execute()\n  except
          errors.HttpError as err:\n    print(err)\n  except:\n    print(''Unexpected
          error'')\n\n  print(response)\n\n  best_trial = response[''trainingOutput''][''trials''][0]\n\n  metric_value
          = best_trial[''finalMetric''][''objectiveValue'']\n  alpha = float(best_trial[''hyperparameters''][''alpha''])\n  max_iter
          = int(best_trial[''hyperparameters''][''max_iter''])\n\n  return (metric_value,
          alpha, max_iter)\n\ndef _serialize_float(float_value: float) -> str:\n    if
          isinstance(float_value, str):\n        return float_value\n    if not isinstance(float_value,
          (float, int)):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead
          of float.''.format(str(float_value), str(type(float_value))))\n    return
          str(float_value)\n\ndef _serialize_int(int_value: int) -> str:\n    if isinstance(int_value,
          str):\n        return int_value\n    if not isinstance(int_value, int):\n        raise
          TypeError(''Value \"{}\" has type \"{}\" instead of int.''.format(str(int_value),
          str(type(int_value))))\n    return str(int_value)\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Retrieve best run'', description=''Retrieves
          the parameters of the best Hypertune run.'')\n_parser.add_argument(\"--project-id\",
          dest=\"project_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--job-id\",
          dest=\"job_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=3)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = retrieve_best_run(**_parsed_args)\n\n_output_serializers
          = [\n    _serialize_float,\n    _serialize_float,\n    _serialize_int,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "gcr.io/robotic-tide-284315/base_image:latest"}}, "inputs": [{"name":
          "project_id", "type": "String"}, {"name": "job_id", "type": "String"}],
          "name": "Retrieve best run", "outputs": [{"name": "metric_value", "type":
          "Float"}, {"name": "alpha", "type": "Float"}, {"name": "max_iter", "type":
          "Integer"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"job_id":
          "{{inputs.parameters.submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id}}",
          "project_id": "{{inputs.parameters.project_id}}"}'}
  - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step
    container:
      args: [--ui_metadata_path, /tmp/outputs/MLPipeline_UI_metadata/data, kfp_component.google.ml_engine,
        train, --project_id, '{{inputs.parameters.project_id}}', --python_module,
        '', --package_uris, '', --region, '{{inputs.parameters.region}}', --args,
        '["--training_dataset_path", "{{inputs.parameters.prepoc-split-dataset-training_file_path}}",
          "--validation_dataset_path", "{{inputs.parameters.prepoc-split-dataset-validation_file_path}}",
          "--hptune", "True"]', --job_dir, '{{inputs.parameters.gcs_root}}/jobdir/hypertune/{{workflow.uid}}',
        --python_version, '', --runtime_version, '', --master_image_uri, 'gcr.io/robotic-tide-284315/trainer_image:latest',
        --worker_image_uri, '', --training_input, '{{inputs.parameters.hypertune_settings}}',
        --job_id_prefix, '', --wait_interval, '30']
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: gcs_root}
      - {name: hypertune_settings}
      - {name: prepoc-split-dataset-training_file_path}
      - {name: prepoc-split-dataset-validation_file_path}
      - {name: project_id}
      - {name: region}
    outputs:
      parameters:
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id
        valueFrom: {path: /tmp/kfp/output/ml_engine/job_id.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_dir, path: /tmp/kfp/output/ml_engine/job_dir.txt}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-job_id, path: /tmp/kfp/output/ml_engine/job_id.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.6.4
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine
          training job as a step in a pipeline.\n", "implementation": {"container":
          {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline UI metadata"},
          "kfp_component.google.ml_engine", "train", "--project_id", {"inputValue":
          "project_id"}, "--python_module", {"inputValue": "python_module"}, "--package_uris",
          {"inputValue": "package_uris"}, "--region", {"inputValue": "region"}, "--args",
          {"inputValue": "args"}, "--job_dir", {"inputValue": "job_dir"}, "--python_version",
          {"inputValue": "python_version"}, "--runtime_version", {"inputValue": "runtime_version"},
          "--master_image_uri", {"inputValue": "master_image_uri"}, "--worker_image_uri",
          {"inputValue": "worker_image_uri"}, "--training_input", {"inputValue": "training_input"},
          "--job_id_prefix", {"inputValue": "job_id_prefix"}, "--wait_interval", {"inputValue":
          "wait_interval"}], "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs":
          {"job_dir": "/tmp/kfp/output/ml_engine/job_dir.txt", "job_id": "/tmp/kfp/output/ml_engine/job_id.txt"},
          "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "Required. The ID of the parent project of the
          job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description":
          "The Python module name to run after installing the packages.", "name":
          "python_module", "type": "String"}, {"default": "", "description": "The
          Cloud Storage location of the packages (that contain the training program  and
          any additional dependencies). The maximum number of package URIs is 100.",
          "name": "package_uris", "type": "List"}, {"default": "", "description":
          "The Compute Engine region in which the training job is run.", "name": "region",
          "type": "GCPRegion"}, {"default": "", "description": "The command line arguments
          to pass to the program.", "name": "args", "type": "List"}, {"default": "",
          "description": "A Cloud Storage path in which to store the training outputs
          and other data  needed for training. This path is passed to your TensorFlow
          program as the  `job-dir` command-line argument. The benefit of specifying
          this field is  that Cloud ML validates the path for use in training.", "name":
          "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version
          of Python used in training. If not set, the default version is `2.7`. Python
          `3.5` is available when runtimeVersion is set to `1.4` and above.", "name":
          "python_version", "type": "String"}, {"default": "", "description": "The
          Cloud ML Engine runtime version to use for training. If not set, Cloud ML
          Engine uses the default stable version, 1.0.", "name": "runtime_version",
          "type": "String"}, {"default": "", "description": "The Docker image to run
          on the master replica. This image must be in Container Registry.", "name":
          "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The
          Docker image to run on the worker replica. This image must be in Container
          Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default":
          "", "description": "The input parameters to create a training job. It is
          the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)",
          "name": "training_input", "type": "Dict"}, {"default": "", "description":
          "The prefix of the generated job id.", "name": "job_id_prefix", "type":
          "String"}, {"default": "30", "description": "Optional. A time-interval to
          wait for between calls to get the job status.  Defaults to 30.''", "name":
          "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env":
          "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step",
          "outputs": [{"description": "The ID of the created job.", "name": "job_id",
          "type": "String"}, {"description": "The output path in Cloud Storage of
          the trainning job, which contains  the trained model files.", "name": "job_dir",
          "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "c05c450e73cf6fc6fd702d86fb6ae06734a7a69f6281d5175e842be39394e206",
          "name": "ml_engine/train", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/ml_engine/train/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"args": "[\"--training_dataset_path\",
          \"{{inputs.parameters.prepoc-split-dataset-training_file_path}}\", \"--validation_dataset_path\",
          \"{{inputs.parameters.prepoc-split-dataset-validation_file_path}}\", \"--hptune\",
          \"True\"]", "job_dir": "{{inputs.parameters.gcs_root}}/jobdir/hypertune/{{workflow.uid}}",
          "job_id_prefix": "", "master_image_uri": "gcr.io/robotic-tide-284315/trainer_image:latest",
          "package_uris": "", "project_id": "{{inputs.parameters.project_id}}", "python_module":
          "", "python_version": "", "region": "{{inputs.parameters.region}}", "runtime_version":
          "", "training_input": "{{inputs.parameters.hypertune_settings}}", "wait_interval":
          "30", "worker_image_uri": ""}'}
  - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2
    container:
      args: [--ui_metadata_path, /tmp/outputs/MLPipeline_UI_metadata/data, kfp_component.google.ml_engine,
        train, --project_id, '{{inputs.parameters.project_id}}', --python_module,
        '', --package_uris, '', --region, '{{inputs.parameters.region}}', --args,
        '["--training_dataset_path", "{{inputs.parameters.prepoc-split-dataset-training_file_path}}",
          "--validation_dataset_path", "{{inputs.parameters.prepoc-split-dataset-validation_file_path}}",
          "--alpha", "{{inputs.parameters.retrieve-best-run-alpha}}", "--max_iter",
          "{{inputs.parameters.retrieve-best-run-max_iter}}", "--hptune", "False"]',
        --job_dir, '{{inputs.parameters.gcs_root}}/jobdir/{{workflow.uid}}', --python_version,
        '', --runtime_version, '', --master_image_uri, 'gcr.io/robotic-tide-284315/trainer_image:latest',
        --worker_image_uri, '', --training_input, '', --job_id_prefix, '', --wait_interval,
        '30']
      command: []
      env:
      - {name: KFP_POD_NAME, value: '{{pod.name}}'}
      - name: KFP_POD_NAME
        valueFrom:
          fieldRef: {fieldPath: metadata.name}
      - name: KFP_NAMESPACE
        valueFrom:
          fieldRef: {fieldPath: metadata.namespace}
      - name: WORKFLOW_ID
        valueFrom:
          fieldRef: {fieldPath: 'metadata.labels[''workflows.argoproj.io/workflow'']'}
      image: gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8
    inputs:
      parameters:
      - {name: gcs_root}
      - {name: prepoc-split-dataset-training_file_path}
      - {name: prepoc-split-dataset-validation_file_path}
      - {name: project_id}
      - {name: region}
      - {name: retrieve-best-run-alpha}
      - {name: retrieve-best-run-max_iter}
    outputs:
      parameters:
      - name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir
        valueFrom: {path: /tmp/kfp/output/ml_engine/job_dir.txt}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/outputs/MLPipeline_UI_metadata/data}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_dir, path: /tmp/kfp/output/ml_engine/job_dir.txt}
      - {name: submitting-a-cloud-ml-training-job-as-a-pipeline-step-2-job_id, path: /tmp/kfp/output/ml_engine/job_id.txt}
    metadata:
      labels:
        add-pod-env: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.6.4
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "A Kubeflow
          Pipeline component to submit a Cloud Machine Learning (Cloud ML) \nEngine
          training job as a step in a pipeline.\n", "implementation": {"container":
          {"args": ["--ui_metadata_path", {"outputPath": "MLPipeline UI metadata"},
          "kfp_component.google.ml_engine", "train", "--project_id", {"inputValue":
          "project_id"}, "--python_module", {"inputValue": "python_module"}, "--package_uris",
          {"inputValue": "package_uris"}, "--region", {"inputValue": "region"}, "--args",
          {"inputValue": "args"}, "--job_dir", {"inputValue": "job_dir"}, "--python_version",
          {"inputValue": "python_version"}, "--runtime_version", {"inputValue": "runtime_version"},
          "--master_image_uri", {"inputValue": "master_image_uri"}, "--worker_image_uri",
          {"inputValue": "worker_image_uri"}, "--training_input", {"inputValue": "training_input"},
          "--job_id_prefix", {"inputValue": "job_id_prefix"}, "--wait_interval", {"inputValue":
          "wait_interval"}], "env": {"KFP_POD_NAME": "{{pod.name}}"}, "fileOutputs":
          {"job_dir": "/tmp/kfp/output/ml_engine/job_dir.txt", "job_id": "/tmp/kfp/output/ml_engine/job_id.txt"},
          "image": "gcr.io/ml-pipeline/ml-pipeline-gcp:e66dcb18607406330f953bf99b04fe7c3ed1a4a8"}},
          "inputs": [{"description": "Required. The ID of the parent project of the
          job.", "name": "project_id", "type": "GCPProjectID"}, {"default": "", "description":
          "The Python module name to run after installing the packages.", "name":
          "python_module", "type": "String"}, {"default": "", "description": "The
          Cloud Storage location of the packages (that contain the training program  and
          any additional dependencies). The maximum number of package URIs is 100.",
          "name": "package_uris", "type": "List"}, {"default": "", "description":
          "The Compute Engine region in which the training job is run.", "name": "region",
          "type": "GCPRegion"}, {"default": "", "description": "The command line arguments
          to pass to the program.", "name": "args", "type": "List"}, {"default": "",
          "description": "A Cloud Storage path in which to store the training outputs
          and other data  needed for training. This path is passed to your TensorFlow
          program as the  `job-dir` command-line argument. The benefit of specifying
          this field is  that Cloud ML validates the path for use in training.", "name":
          "job_dir", "type": "GCSPath"}, {"default": "", "description": "The version
          of Python used in training. If not set, the default version is `2.7`. Python
          `3.5` is available when runtimeVersion is set to `1.4` and above.", "name":
          "python_version", "type": "String"}, {"default": "", "description": "The
          Cloud ML Engine runtime version to use for training. If not set, Cloud ML
          Engine uses the default stable version, 1.0.", "name": "runtime_version",
          "type": "String"}, {"default": "", "description": "The Docker image to run
          on the master replica. This image must be in Container Registry.", "name":
          "master_image_uri", "type": "GCRPath"}, {"default": "", "description": "The
          Docker image to run on the worker replica. This image must be in Container
          Registry.", "name": "worker_image_uri", "type": "GCRPath"}, {"default":
          "", "description": "The input parameters to create a training job. It is
          the JSON payload  of a [TrainingInput](https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#TrainingInput)",
          "name": "training_input", "type": "Dict"}, {"default": "", "description":
          "The prefix of the generated job id.", "name": "job_id_prefix", "type":
          "String"}, {"default": "30", "description": "Optional. A time-interval to
          wait for between calls to get the job status.  Defaults to 30.''", "name":
          "wait_interval", "type": "Integer"}], "metadata": {"labels": {"add-pod-env":
          "true"}}, "name": "Submitting a Cloud ML training job as a pipeline step",
          "outputs": [{"description": "The ID of the created job.", "name": "job_id",
          "type": "String"}, {"description": "The output path in Cloud Storage of
          the trainning job, which contains  the trained model files.", "name": "job_dir",
          "type": "GCSPath"}, {"name": "MLPipeline UI metadata", "type": "UI metadata"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "c05c450e73cf6fc6fd702d86fb6ae06734a7a69f6281d5175e842be39394e206",
          "name": "ml_engine/train", "url": "https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/ml_engine/train/component.yaml"}',
        pipelines.kubeflow.org/arguments.parameters: '{"args": "[\"--training_dataset_path\",
          \"{{inputs.parameters.prepoc-split-dataset-training_file_path}}\", \"--validation_dataset_path\",
          \"{{inputs.parameters.prepoc-split-dataset-validation_file_path}}\", \"--alpha\",
          \"{{inputs.parameters.retrieve-best-run-alpha}}\", \"--max_iter\", \"{{inputs.parameters.retrieve-best-run-max_iter}}\",
          \"--hptune\", \"False\"]", "job_dir": "{{inputs.parameters.gcs_root}}/jobdir/{{workflow.uid}}",
          "job_id_prefix": "", "master_image_uri": "gcr.io/robotic-tide-284315/trainer_image:latest",
          "package_uris": "", "project_id": "{{inputs.parameters.project_id}}", "python_module":
          "", "python_version": "", "region": "{{inputs.parameters.region}}", "runtime_version":
          "", "training_input": "", "wait_interval": "30", "worker_image_uri": ""}'}
  arguments:
    parameters:
    - {name: project_id}
    - {name: region}
    - {name: gcs_root}
    - {name: dataset_id}
    - {name: evaluation_metric_name}
    - {name: evaluation_metric_threshold}
    - {name: model_id}
    - {name: version_id}
    - {name: replace_existing_version}
    - name: hypertune_settings
      value: |2

        {
            "hyperparameters":  {
                "goal": "MAXIMIZE",
                "maxTrials": 6,
                "maxParallelTrials": 3,
                "hyperparameterMetricTag": "accuracy",
                "enableTrialEarlyStopping": True,
                "params": [
                    {
                        "parameterName": "max_iter",
                        "type": "DISCRETE",
                        "discreteValues": [90, 100]
                    },
                    {
                        "parameterName": "alpha",
                        "type": "DOUBLE",
                        "minValue": 0.001,
                        "maxValue": 0.004,
                        "scaleType": "UNIT_LINEAR_SCALE"
                    }
                ]
            }
        }
    - {name: dataset_location, value: US}
  serviceAccountName: pipeline-runner
